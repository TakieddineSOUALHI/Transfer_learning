{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_distillation_solution_avec_temperature",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVHiUMDC55Do"
      },
      "source": [
        "# Travail préparatoire\n",
        "\n",
        "Avant de commencer le TP, nous vous recommandons fortement de :\n",
        "- Suivre le tutoriel [Customize what happens in Model.fit](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit)\n",
        "- Vous reporter si besoin à la documentation de la classe [``` Model ```](https://www.tensorflow.org/api_docs/python/tf/keras/Model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njiSyopM0Phb"
      },
      "source": [
        "# Objectifs \n",
        "\n",
        "Les objectifs de ce TP sont : \n",
        "- Découvrir le principe de la compression des réseaux de neurones par distillation (cf: Hinton et al., [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531))\n",
        "\n",
        "- Illustrer la flexibilité du paradigme des réseaux de neurones profonds\n",
        "\n",
        "- Apprendre à utiliser la classe ``` Model ``` et à redéfinir certaines de ses méthodes (cf. travail préparatoire)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFFpwfOP6u-D"
      },
      "source": [
        "# Travail à réaliser \n",
        "\n",
        "Lors de ce TP, nous allons réaliser la distillation d'un réseau de neurones de type CNN (le *Teacher*) dans un réseau plus léger (le \"Student\"). Pour ce cas d'étude nous utiliserons la base MNIST que nous avons déjà utilisé lors des TP précédents. \n",
        "Vous allez donc devoir : \n",
        "- Définir l'architecture du réseau *Teacher* et optimiser le modèle sur la base MNIST (à noter que vous pouvez également utiliser un modèle pré-appris pour la tâche qui nous intéresse, ici la reconnaissance de chiffre manuscript)\n",
        "- Définir l'architecture du réseau léger *Student*\n",
        "- Préparer les données d'apprentissage qui serviront à la distillation. Nous utiliserons les données de MNIST (les mêmes que celles qui ont servi à l'apprentissage du Teacher, mais ce n'est pas une obligation, les deux bases peuvent être différentes, seules les tâches à réaliser doivent être identiques)\n",
        "- Implémenter la classe *Distiller* qui sera en charge de la distillation. \n",
        "\n",
        "La classe ``` Distiller ``` héritera de la classe ``` Model ``` pour laquelle il faudra redéfinir le constructeur, et les méthodes ``` train_step ``` et ``` test_step ```. Vous pourrez également redéfinir la méthode ``` compile ``` si vous souhaitez faire un code plus générique et tester différentes fonctions de coût et hyper-paramètre propre à la méthode de distillation.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y9Z1RjL0G3W"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOeaMjs1AYhX"
      },
      "source": [
        "## Préparation des données "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj5ek6I-AVks"
      },
      "source": [
        "## Chargement et normalisation des données\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# POUR LES CNN : On rajoute une dimension pour spécifier qu'il s'agit d'images en NdG\n",
        "train_images = train_images.reshape(-1,28,28,1)\n",
        "test_images = test_images.reshape(-1,28,28,1)\n",
        "\n",
        "# One hot encoding\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-YCwXQ9Bjbb"
      },
      "source": [
        "## Définition et apprentissage de modèle ```teacher```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atN9jNfVShYG"
      },
      "source": [
        "Définition du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK4PLyYyArHj"
      },
      "source": [
        "## DEFINITION DES MODELES\n",
        "## Teacher \n",
        "## Définition de l'architecture du modèle\n",
        "teacher = tf.keras.models.Sequential()\n",
        "teacher.add(tf.keras.layers.Conv2D(filters=16,kernel_size=(3,3),padding=\"same\", activation='relu', input_shape=(28, 28, 1)))\n",
        "teacher.add(tf.keras.layers.AveragePooling2D())\n",
        "teacher.add(tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),padding=\"same\", activation='relu'))\n",
        "teacher.add(tf.keras.layers.AveragePooling2D())\n",
        "teacher.add(tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation='relu'))\n",
        "teacher.add(tf.keras.layers.AveragePooling2D())\n",
        "teacher.add(tf.keras.layers.Flatten())\n",
        "teacher.add(tf.keras.layers.Dense(1024 , activation='relu'))\n",
        "teacher.add(tf.keras.layers.Dense(512 , activation='relu'))\n",
        "teacher.add(tf.keras.layers.Dense(10))\n",
        "print(teacher.summary())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygDhB7S5S1fS"
      },
      "source": [
        "Apprentissage du modèle (Adam + Entropie Croisée sur 10 epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQeuN3spSXmv"
      },
      "source": [
        "load_teacher = False\n",
        "\n",
        "if (load_teacher == True):\n",
        "  teacher = tf.keras.models.load_model('saved_teacher_with_T')\n",
        "else:\n",
        "  teacher.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(), \n",
        "      loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
        "      metrics=tf.keras.metrics.CategoricalAccuracy()\n",
        "    )\n",
        "\n",
        "  teacher.fit(train_images, train_labels,batch_size=64,epochs=20)\n",
        "  tf.keras.models.save_model(\n",
        "      teacher, 'saved_teacher_with_T', overwrite=True, include_optimizer=True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbycKD3hS-Au"
      },
      "source": [
        "Evaluation des performances sur la base de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC09Fo-LTWD1"
      },
      "source": [
        "teacher.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TFf7vtFTgwm"
      },
      "source": [
        "## Définition du modèle  ```student```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eusdDqyTpge"
      },
      "source": [
        "## Student\n",
        "student = tf.keras.models.Sequential()\n",
        "# Expliquez à quoi correspondent les valeurs numériques qui définissent les couches du réseau\n",
        "student.add(tf.keras.layers.Conv2D(filters=8,kernel_size=(3,3),padding=\"same\", activation='relu', input_shape=(28, 28, 1)))\n",
        "student.add(tf.keras.layers.AveragePooling2D())\n",
        "student.add(tf.keras.layers.Conv2D(filters=8,kernel_size=(3,3),padding=\"same\", activation='relu'))\n",
        "student.add(tf.keras.layers.AveragePooling2D())\n",
        "student.add(tf.keras.layers.Flatten())\n",
        "student.add(tf.keras.layers.Dense(64 , activation='relu'))\n",
        "student.add(tf.keras.layers.Dense(32 , activation='relu'))\n",
        "student.add(tf.keras.layers.Dense(10))\n",
        "# expliquer le nombre de paramètre de ce réseau\n",
        "print(student.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnYtj6Rey9hE"
      },
      "source": [
        "# On copie l'instance \n",
        "student_loss_sup =  tf.keras.models.clone_model(student)\n",
        "student_loss_distillation =  tf.keras.models.clone_model(student)\n",
        "student_loss_both =  tf.keras.models.clone_model(student)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tlWJGEdUCUj"
      },
      "source": [
        "##Définition de la classe ``` Distiller ```\n",
        "\n",
        "Le distiller a besoin du modèle ``` teacher ``` appris et de modèle ``` student ``` \n",
        "\n",
        "Les méthodes ``` train_step ``` et ``` test_step ``` doit être redéfinies et seront appelées respectivement par les méthodes ``` fit ``` et  ``` evaluate ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KAUPyWbT350"
      },
      "source": [
        "class Distiller(Model):\n",
        "\n",
        "    def __init__(self, teacher, student, alpha, T):\n",
        "        super(Distiller, self).__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "        self.alpha = alpha\n",
        "        self.T = T\n",
        "    \n",
        "    def train_step(self, data):\n",
        "        # on récupère les données\n",
        "        img_batch, label_batch = data\n",
        "\n",
        "        # Prediction du teacher (pour guider l'apprentissage du student)\n",
        "        pred_teacher = self.teacher(img_batch)\n",
        "        \n",
        "        # Prédition du student\n",
        "        with tf.GradientTape() as tape: \n",
        "            pred_student = self.student(img_batch)\n",
        "            loss_distillation = tf.keras.losses.categorical_crossentropy(\n",
        "                tf.nn.softmax(pred_teacher / self.T, axis=1),\n",
        "                tf.nn.softmax(pred_student / self.T, axis=1),               \n",
        "               from_logits = True\n",
        "              )\n",
        "            loss_sup = tf.keras.losses.categorical_crossentropy(\n",
        "                label_batch,\n",
        "                pred_student,\n",
        "                from_logits = True\n",
        "              )\n",
        "            loss = self.alpha*loss_distillation + (1-self.alpha)*loss_sup\n",
        "\n",
        "\n",
        "\n",
        "        # Calcul des gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Mise à jour des poids\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`. Necessaire ? pas dans compile)\n",
        "        self.compiled_metrics.update_state(label_batch, pred_student)\n",
        "\n",
        "        # Retourne un dictionnaire avec le résultats\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\n",
        "                \"loss_distillation\": loss_distillation, \n",
        "                \"loss_sup\": loss_sup, \n",
        "                \"loss\": loss\n",
        "            }\n",
        "        )\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # on récupère les données\n",
        "        img_batch, label_batch = data\n",
        "        # Compute predictions\n",
        "        pred_student = self.student(img_batch, training=False)\n",
        "\n",
        "        # Calculate the loss\n",
        "        student_loss = tf.keras.losses.categorical_crossentropy(label_batch, pred_student, from_logits=True)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(label_batch, pred_student)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": student_loss})\n",
        "        return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sjWOGz9XRi0"
      },
      "source": [
        "## Distillation du modèle "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DivT3clQXhHe"
      },
      "source": [
        "Apprentissage du modèle léger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMh4Ob4eVlR5"
      },
      "source": [
        "# Uniquement la loss superviée\n",
        "distiller = Distiller(student=student_loss_sup, teacher=teacher, alpha=1, T=1)\n",
        "distiller.compile(optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.CategoricalAccuracy(name='précision :')])\n",
        "distiller.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imp9rVexXcNT"
      },
      "source": [
        "Evaluation du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soURiST-XeTg"
      },
      "source": [
        "distiller.evaluate(test_images, test_labels, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQX6M-PFXqCa"
      },
      "source": [
        "# Uniquement la loss distillation\n",
        "distiller = Distiller(student=student_loss_sup, teacher=teacher, alpha=1, T=1)\n",
        "distiller.compile(optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.CategoricalAccuracy(name='précision :')])\n",
        "distiller.fit(train_images, train_labels, epochs=5)\n",
        "distiller.evaluate(test_images, test_labels, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3yAwsFN1_dp"
      },
      "source": [
        "# les 2 loss\n",
        "distiller = Distiller(student=student_loss_both, teacher=teacher, alpha=0.5, T=1)\n",
        "distiller.compile(optimizer=tf.keras.optimizers.Adam(), metrics=[tf.keras.metrics.CategoricalAccuracy(name='précision :')])\n",
        "distiller.fit(train_images, train_labels, epochs=5)\n",
        "distiller.evaluate(test_images, test_labels, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkU-gwaI6Ttb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMKiPMxs9Hap"
      },
      "source": [
        "Dans ce TP, nous avons implémenté et évaluer une stratégie de distillation de l'information d'un réseau Teacher (expert) vers un réseau Student La distillation peut-être utilisée pour :\n",
        "- compresser la taille (nombre de paramètre) d'un réseau expert\n",
        "- spécialiser un réseau léger pour un domaine particulier\n",
        "- apprendre un réseau lorsque l'on dispose d'un (ou plusieurs) réseau mais pas de données annotées. \n",
        "\n",
        "\n",
        "Vous pouvez également tester cette stratégie sur : \n",
        "- d'autres bases (e.g. CIFAR 10)\n",
        "- en utilisant des réseaux pré-apris disponibles dans TF2 (eg: https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1) -> cf: https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub pour un exemple d'utilisation de modèles pré-appris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmq3uNMh-Kj7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}